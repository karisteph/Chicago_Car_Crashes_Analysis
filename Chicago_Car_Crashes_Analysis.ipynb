{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago Car Crashes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction text to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three distinct datasets are used in this analysis:\n",
    "- Crashes\n",
    "- People\n",
    "- Socially Disadvantaged Districts\n",
    "\n",
    "These datasets are large.  Specifying the specific columns to import for each dataset will limit the time it takes to bring them into dataframes, and will minimize system resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_usecols = ['LATITUDE','LONGITUDE','CRASH_RECORD_ID','CRASH_DATE','DEVICE_CONDITION',\\\n",
    "                   'WEATHER_CONDITION','LIGHTING_CONDITION','ALIGNMENT','ROADWAY_SURFACE_COND',\\\n",
    "                   'INJURIES_FATAL','INJURIES_INCAPACITATING','CRASH_HOUR','CRASH_DAY_OF_WEEK']\n",
    "\n",
    "people_usecols = ['CRASH_RECORD_ID','SAFETY_EQUIPMENT','PHYSICAL_CONDITION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV files into DataFrames\n",
    "crashes_df = pd.read_csv('Data/Traffic_Crashes_-_Crashes_20240412.csv', usecols=crashes_usecols)\n",
    "people_df = pd.read_csv('Data/Traffic_Crashes_-_People_20240412.csv', usecols=people_usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SHP file into a GeoDataFrame\n",
    "districts_gdf = gpd.read_file('Data\\SD_geo.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing discussion - for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crashes dataset\n",
    "- Create flag for records within disadvantaged districts\n",
    "- Create bins for: (1) roadway conditions, (2) roadway alignment, (3) roadway devices, (4) weather, (5) lighting, and (6) surface conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographic analysis\n",
    "- Drop records without locations\n",
    "- Convert the Crashes DataFrame into a GeoDataFrame so that the coordinates can be turned into Points using the Shapely package\n",
    "- Ensure that the resulting GDF uses the same reference system as the imported districts GDF\n",
    "- Spatially join the two GDFs, checking to see if each point is within one of the districts and assigning 1's to those\n",
    "- Drop unnecessary columns and convert back to a DataFrame, which is computationally more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop values with no location information\n",
    "crashes_df.dropna(subset=['LATITUDE','LONGITUDE'], inplace=True)\n",
    "\n",
    "# Convert DataFrame into GeoDataFrame\n",
    "crashes_df['geometry'] = crashes_df.apply(lambda row: Point(row['LONGITUDE'], row['LATITUDE']), axis=1)\n",
    "crashes_gdf = gpd.GeoDataFrame(crashes_df, geometry='geometry')\n",
    "\n",
    "# Ensure that both GeoDataFrames use the same CRS\n",
    "crashes_gdf.crs = districts_gdf.crs\n",
    "\n",
    "# Spatial join the GeoDataFrames\n",
    "joined_gdf = gpd.sjoin(crashes_gdf, districts_gdf, how='left', predicate='within')\n",
    "\n",
    "# Add flag for crashes that are within a district\n",
    "joined_gdf['WITHIN_DISTRICT'] = joined_gdf['index_right'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "\n",
    "# Drop the geometry, index_right, LATITUDE and LONGITUDE columns\n",
    "joined_gdf.drop(columns=['LATITUDE','LONGITUDE','geometry','index_right'], axis=1, inplace=True)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "crashes_flag_df = pd.DataFrame(joined_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare datetime data for analysis\n",
    "- Create a helper function to convert each date to a season\n",
    "- Convert each date string to a season\n",
    "- Group days of the week into weekday/weekend categories\n",
    "- Group hours of the day into thematic blocks\n",
    "- Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert dates to seasons\n",
    "\n",
    "def get_season(date):\n",
    "    year = date.year\n",
    "    seasons = [('winter', datetime(year, 1, 1).date(), datetime(year, 2, 28).date()),\n",
    "               ('spring', datetime(year, 3, 1).date(), datetime(year, 5, 31).date()),\n",
    "               ('summer', datetime(year, 6, 1).date(), datetime(year, 8, 31).date()),\n",
    "               ('autumn', datetime(year, 9, 1).date(), datetime(year, 11, 30).date()),\n",
    "               ('winter', datetime(year, 12, 1).date(), datetime(year, 12, 31).date())]\n",
    "    if date.year % 4 == 0:  # leap year check\n",
    "        seasons[0] = ('winter', datetime(year, 1, 1).date(), datetime(year, 2, 29).date())\n",
    "    \n",
    "    for season, start, end in seasons:\n",
    "        if start <= date <= end:\n",
    "            return season\n",
    "\n",
    "    return 'Date is out of range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date field to season\n",
    "crashes_flag_df['SEASON'] = crashes_flag_df['CRASH_DATE'].apply(lambda x: \n",
    "                                                      get_season(datetime.strptime(x[:10],'%m/%d/%Y').date()))\n",
    "\n",
    "# Group CRASH_DAY_OF_WEEK into weekdays and weekends\n",
    "weekday_mask = [2,3,4,5,6]\n",
    "crashes_flag_df['WEEKEND'] = crashes_flag_df['CRASH_DAY_OF_WEEK'].apply(lambda x: 0 if x in weekday_mask else 1)\n",
    "\n",
    "# Group hours into time blocks (extra bin at end to ensure correct bin treatment)\n",
    "bins = [-1, 6, 9, 15, 19, 23, 24]\n",
    "labels = ['night', 'morning_rush', 'midday', 'evening_rush', 'night', 'night']\n",
    "crashes_flag_df['TIME_BLOCK'] = pd.cut(crashes_flag_df['CRASH_HOUR'], bins=bins, labels=labels, right=True, ordered=False)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "crashes_flag_df.drop(columns=['CRASH_DATE','CRASH_DAY_OF_WEEK','CRASH_HOUR'], axis=1, inplace=True)                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category flags\n",
    "- Convert string categories into 1/0 where 1's signify potential dangerous conditions\n",
    "- Categories include malfunctioning road device, bad weather conditions, poor lighting, non-straight and level roads and unsafe surfaces\n",
    "- Create a target column equal to 1 if there are any fatal or incapacitating injuries\n",
    "- Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_mask = ['NO CONTROLS','FUNCTIONING PROPERLY']\n",
    "weather_mask = ['CLEAR','UNKNOWN']\n",
    "lighting_mask = ['DAYLIGHT']\n",
    "alignment_mask = ['STRAIGHT AND LEVEL']\n",
    "surface_mask = ['DRY','UNKNOWN']\n",
    "\n",
    "crashes_flag_df['DEVICE_FLAG'] = crashes_flag_df['DEVICE_CONDITION'].apply(lambda x: 0 if x in device_mask else 1)\n",
    "crashes_flag_df['WEATHER_FLAG'] = crashes_flag_df['WEATHER_CONDITION'].apply(lambda x: 0 if x in weather_mask else 1)\n",
    "crashes_flag_df['LIGHTING_FLAG'] = crashes_flag_df['LIGHTING_CONDITION'].apply(lambda x: 0 if x in lighting_mask else 1)\n",
    "crashes_flag_df['ALIGNMENT_FLAG'] = crashes_flag_df['ALIGNMENT'].apply(lambda x: 0 if x in alignment_mask else 1)\n",
    "crashes_flag_df['SURFACE_FLAG'] = crashes_flag_df['ROADWAY_SURFACE_COND'].apply(lambda x: 0 if x in surface_mask else 1)\n",
    "\n",
    "# Flag for serious accidents (fatal + incapacitating), which is the target\n",
    "crashes_flag_df['TARGET'] = crashes_flag_df.apply(lambda row: 1 if \n",
    "                                                  (row['INJURIES_FATAL']+row['INJURIES_INCAPACITATING'] > 0) else 0,\n",
    "                                                  axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "crashes_flag_df = crashes_flag_df.drop(columns=['DEVICE_CONDITION', 'WEATHER_CONDITION', 'LIGHTING_CONDITION',\\\n",
    "                                                'ALIGNMENT', 'ROADWAY_SURFACE_COND',\\\n",
    "                                               'INJURIES_FATAL', 'INJURIES_INCAPACITATING'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### People Dataset\n",
    "This dataset includes all people involved with any crash (e.g. the driver of each car, each passenger), so there is more than one line per crash.  Since this analysis predicts the effect of crashes, all relevant information must be extracted and processed into per-crash form.  This is accomplished by converting each feature into a single flag per crash.\n",
    "- Flag vehicle operators with compromised physical features (e.g. alcohol, drugs, tired)\n",
    "- Flag participants that failed to use vehicle safety equipment properly\n",
    "- Group people by CRASH_ID and apply flag if applicable\n",
    "- Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks to assist in binning the PHYSICAL_CONDITION and SAFETY_EQUIPMENT fields\n",
    "PhysicalMask = ['NORMAL', 'UNKNOWN']\n",
    "SafetyMask = ['SAFETY BELT USED', 'USAGE UNKNOWN', 'CHILD RESTRAINT USED', 'CHILD RESTRAINT - FORWARD FACING'\\\n",
    "             'BICYCLE HELMET (PEDACYCLIST INVOLVED ONLY)', 'CHILD RESTRAINT - TYPE UNKNOWN',\\\n",
    "             'CHILD RESTRAINT - REAR FACING', 'HELMET USED', 'DOT COMPLIANT MOTORCYCLE HELMET',\\\n",
    "             'BOOSTER SEAT', 'WHEELCHAIR', 'STRETCHER']\n",
    "\n",
    "# Bin all problematic physical and safety conditions and tag with a 1 \n",
    "people_df['PHYSICAL_FLAG'] = people_df['PHYSICAL_CONDITION'].apply(lambda x: 0 if x in PhysicalMask else 1)\n",
    "people_df['SAFETY_FLAG'] = people_df['SAFETY_EQUIPMENT'].apply(lambda x: 0 if x in SafetyMask else 1)\n",
    "\n",
    "# Drop the original columns\n",
    "people_df = people_df.drop(columns=['PHYSICAL_CONDITION', 'SAFETY_EQUIPMENT'], axis=1)\n",
    "\n",
    "# For each crash, tag if at least one element had a safety or physical problem\n",
    "safety_flag = people_df.groupby('CRASH_RECORD_ID')['SAFETY_FLAG'].max().reset_index()\n",
    "safety_flag.rename(columns={'SAFETY_FLAG': 'SAFETY_PROBLEM'}, inplace=True)\n",
    "people_df = people_df.drop('SAFETY_FLAG', axis=1).merge(safety_flag, on='CRASH_RECORD_ID', how='left')\n",
    "\n",
    "physical_flag = people_df.groupby('CRASH_RECORD_ID')['PHYSICAL_FLAG'].max().reset_index()\n",
    "physical_flag.rename(columns={'PHYSICAL_FLAG': 'PHYSICAL_PROBLEM'}, inplace=True)\n",
    "people_df = people_df.drop('PHYSICAL_FLAG', axis=1).merge(physical_flag, on='CRASH_RECORD_ID', how='left')\n",
    "\n",
    "# Drop remaining duplicate rows\n",
    "people_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WITHIN_DISTRICT</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>WEEKEND</th>\n",
       "      <th>TIME_BLOCK</th>\n",
       "      <th>DEVICE_FLAG</th>\n",
       "      <th>WEATHER_FLAG</th>\n",
       "      <th>LIGHTING_FLAG</th>\n",
       "      <th>ALIGNMENT_FLAG</th>\n",
       "      <th>SURFACE_FLAG</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>SAFETY_PROBLEM</th>\n",
       "      <th>PHYSICAL_PROBLEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "      <td>1</td>\n",
       "      <td>midday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>summer</td>\n",
       "      <td>0</td>\n",
       "      <td>evening_rush</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>summer</td>\n",
       "      <td>1</td>\n",
       "      <td>midday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>summer</td>\n",
       "      <td>1</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>autumn</td>\n",
       "      <td>0</td>\n",
       "      <td>midday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816539</th>\n",
       "      <td>0</td>\n",
       "      <td>summer</td>\n",
       "      <td>0</td>\n",
       "      <td>midday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816540</th>\n",
       "      <td>1</td>\n",
       "      <td>spring</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816541</th>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>0</td>\n",
       "      <td>evening_rush</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816542</th>\n",
       "      <td>0</td>\n",
       "      <td>spring</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816543</th>\n",
       "      <td>1</td>\n",
       "      <td>summer</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816544 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WITHIN_DISTRICT  SEASON  WEEKEND    TIME_BLOCK  DEVICE_FLAG  \\\n",
       "0                     1  summer        1        midday            0   \n",
       "1                     0  summer        0  evening_rush            0   \n",
       "2                     0  summer        1        midday            0   \n",
       "3                     0  summer        1         night            0   \n",
       "4                     0  autumn        0        midday            0   \n",
       "...                 ...     ...      ...           ...          ...   \n",
       "816539                0  summer        0        midday            0   \n",
       "816540                1  spring        0         night            1   \n",
       "816541                0  spring        0  evening_rush            0   \n",
       "816542                0  spring        0         night            0   \n",
       "816543                1  summer        0         night            0   \n",
       "\n",
       "        WEATHER_FLAG  LIGHTING_FLAG  ALIGNMENT_FLAG  SURFACE_FLAG  TARGET  \\\n",
       "0                  0              0               0             0       0   \n",
       "1                  0              0               0             0       0   \n",
       "2                  0              1               0             0       0   \n",
       "3                  0              1               0             0       0   \n",
       "4                  0              0               0             0       0   \n",
       "...              ...            ...             ...           ...     ...   \n",
       "816539             0              0               0             0       0   \n",
       "816540             0              1               0             0       0   \n",
       "816541             0              1               0             0       0   \n",
       "816542             1              1               0             1       0   \n",
       "816543             1              1               0             1       0   \n",
       "\n",
       "        SAFETY_PROBLEM  PHYSICAL_PROBLEM  \n",
       "0                    0                 0  \n",
       "1                    1                 0  \n",
       "2                    0                 0  \n",
       "3                    0                 0  \n",
       "4                    0                 0  \n",
       "...                ...               ...  \n",
       "816539               0                 0  \n",
       "816540               0                 0  \n",
       "816541               0                 0  \n",
       "816542               0                 0  \n",
       "816543               0                 0  \n",
       "\n",
       "[816544 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframes\n",
    "combined_df = crashes_flag_df.merge(people_df, on='CRASH_RECORD_ID', how='inner')\n",
    "\n",
    "# Convert TIME_BLOCK and SEASON to type='category'\n",
    "combined_df['TIME_BLOCK'] = combined_df['TIME_BLOCK'].astype('category')\n",
    "combined_df['SEASON'] = combined_df['SEASON'].astype('category')\n",
    "\n",
    "# Drop CRASH_RECORD_ID\n",
    "combined_df.drop('CRASH_RECORD_ID', axis=1, inplace=True)\n",
    "\n",
    "# Reset index\n",
    "combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- Baseline model\n",
    "- Simple first model\n",
    "- Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined_df['TARGET']\n",
    "X = combined_df.drop('TARGET', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets, stratify the split to ensure sufficient targets are in test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1023, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model\n",
    "Our target variable is imbalanced.  The baseline model is a dummy classifier that selects for most frequent value.  Since over 98% of all crashes do not result in a fatality or serious injury, accuracy in this baseline model will be very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9819667011616017\n",
      "Baseline ROC-AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "print(\"Baseline Accuracy:\", dummy_clf.score(X_test, y_test))\n",
    "print(\"Baseline ROC-AUC:\", roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First simple model\n",
    "As a first test to improve on the baseline, this model uses a decision tree with three variables:\n",
    "- Weather\n",
    "- The driver's use of appropriate safety features\n",
    "- Driver's physical condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rick\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    160364\n",
      "           1       0.00      0.00      0.00      2945\n",
      "\n",
      "    accuracy                           0.98    163309\n",
      "   macro avg       0.49      0.50      0.50    163309\n",
      "weighted avg       0.96      0.98      0.97    163309\n",
      "\n",
      "Logistic Regression ROC-AUC: 0.752348885911038\n"
     ]
    }
   ],
   "source": [
    "# Select variables for simple model\n",
    "simple_cols = ['WEATHER_FLAG', 'SAFETY_PROBLEM', 'PHYSICAL_PROBLEM']\n",
    "X_train_simple = X_train[simple_cols]\n",
    "X_test_simple = X_test[simple_cols]\n",
    "\n",
    "# Instantiate a logistic regression\n",
    "logreg_simple = LogisticRegression()\n",
    "logreg_simple.fit(X_train_simple, y_train)\n",
    "y_pred = logreg_simple.predict(X_test_simple)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Logistic Regression ROC-AUC:\", roc_auc_score(y_test, logreg_simple.predict_proba(X_test_simple)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the severe imbalance in the target variable, the model does not successfully predict *any* positive cases (though the higher ROC-AUC suggests setting a lower probability threshold might lead to better predictions.\n",
    "\n",
    "The next iteration adds many more variables to the regression to add more explanatory power to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rick\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    160364\n",
      "           1       0.00      0.00      0.00      2945\n",
      "\n",
      "    accuracy                           0.98    163309\n",
      "   macro avg       0.49      0.50      0.50    163309\n",
      "weighted avg       0.96      0.98      0.97    163309\n",
      "\n",
      "Logistic Regression ROC-AUC: 0.7743181376121446\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "cat_columns = ['SEASON', 'TIME_BLOCK']\n",
    "\n",
    "# Encode training data\n",
    "X_train_ohe = ohe.fit_transform(X_train[cat_columns])\n",
    "feature_names = ohe.get_feature_names(cat_columns)\n",
    "X_train_ohe_df = pd.DataFrame(X_train_ohe, columns=feature_names, index=X_train.index)\n",
    "X_train_final = pd.concat([X_train.drop(columns=cat_columns, axis=1), X_train_ohe_df], axis=1)\n",
    "\n",
    "# Encode test data\n",
    "X_test_ohe = ohe.transform(X_test[cat_columns])\n",
    "feature_names = ohe.get_feature_names(cat_columns)\n",
    "X_test_ohe_df = pd.DataFrame(X_test_ohe, columns=feature_names, index=X_test.index)\n",
    "X_test_final = pd.concat([X_test.drop(columns=cat_columns, axis=1), X_test_ohe_df], axis=1)\n",
    "\n",
    "logreg_complex = LogisticRegression()\n",
    "logreg_complex.fit(X_train_final, y_train)\n",
    "y_pred_complex = logreg_complex.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred_complex))\n",
    "print(\"Logistic Regression ROC-AUC:\", roc_auc_score(y_test, logreg_complex.predict_proba(X_test_final)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That improved the ROC-AUC marginally, but not the precision or recall.  The class imbalance is too great.\n",
    "\n",
    "The next iteration will use SMOTE to address the imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model with SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the future:\n",
    "- Proximity to holidays\n",
    "- Geographic proximity to hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
